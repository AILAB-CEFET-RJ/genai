{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Chunking\n",
    "- Instead of splitting text at arbitrary lengths, use Natural Language Processing (NLP) to split at meaningful boundaries:\n",
    "- Sentence-based: Use NLP tools like Spacy or NLTK to split by sentences.\n",
    "- Paragraph-based: Treat each paragraph as a chunk.\n",
    "- Heading-based: Use document structure (e.g., titles, headings, subheadings) to define chunks.\n",
    "- Slide-based: If the PDF is a slide deck, extract each slide as a chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ebezerra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download tokenizer model for Portuguese if not already downloaded\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def semantic_chunking(text, max_length=500):\n",
    "    sentences = sent_tokenize(text, language=\"portuguese\")  # Tokenize sentences in Portuguese\n",
    "    chunks, current_chunk = [], \"\"\n",
    "\n",
    "    for sent in sentences:\n",
    "        if len(current_chunk) + len(sent) < max_length:\n",
    "            current_chunk += \" \" + sent\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sent\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Extracting text from PDF...\n"
     ]
    }
   ],
   "source": [
    "PDF_FILE = \"../data/propostas/tokio_outubro_2024.pdf\"  # Change this to your PDF file\n",
    "print(\"üìÑ Extracting text from PDF...\")\n",
    "raw_text = extract_text_from_pdf(PDF_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path\n",
    "OUTPUT_FILE = \"../data/tokio_outubro_2024.txt\"  \n",
    "\n",
    "# Save extracted text to a text file\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_footer(text):\n",
    "    \"\"\"\n",
    "    Removes footers matching the given pattern.\n",
    "    \"\"\"\n",
    "    # Define a regex pattern based on your footer structure\n",
    "    footer_pattern = r\"\\d+\\s*\\nTokio Marine Seguradora S\\.A ‚Äì Cia \\d+\\s*\\nCondom√≠nio Processo SUSEP n¬∫ .* - Vers√£o- .*\"\n",
    "\n",
    "    # Remove matching footer patterns\n",
    "    cleaned_text = re.sub(footer_pattern, \"\", text, flags=re.MULTILINE)\n",
    "\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Footer removed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load extracted text from file\n",
    "input_file = \"../data/tokio_outubro_2024.txt\"\n",
    "output_file = \"../data/tokio_outubro_2024_cleaned.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Remove footers\n",
    "cleaned_text = remove_footer(raw_text)\n",
    "\n",
    "# Save cleaned text\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(cleaned_text)\n",
    "\n",
    "print(\"‚úÖ Footer removed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = semantic_chunking(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting summary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"\"\"\n",
    "1. √ÇMBITO GEOGR√ÅFICO............................................................................................................................................................. 8 \n",
    "2. OBJETIVO DO SEGURO ........................................................................................................................................................... 8 \n",
    "3. DOCUMENTOS DO SEGURO ................................................................................................................................................... 8 \n",
    "4. LOCAL DE RISCO ..................................................................................................................................................................... 8 \n",
    "5. EDIF√çCIOS ABRANGIDOS PELO SEGURO.............................................................................................................................. 8 \n",
    "6. EDIF√çCIOS N√ÉO ABRANGIDOS PELO SEGURO..................................................................................................................... 9 \n",
    "7. COBERTURAS DO SEGURO .................................................................................................................................................. 10 \n",
    "7.1 COBERTURA B√ÅSICA AMPLA ........................................................................................................................................... 10 \n",
    "7.2 COBERTURA B√ÅSICA SIMPLES ........................................................................................................................................ 11 \n",
    "8 COBERTURAS ACESS√ìRIAS ........................................................................................................................... 12 \n",
    "8.1 ALAGAMENTO E INUNDA√á√ÉO ......................................................................................................................... 12 \n",
    "8.2 DANOS EL√âTRICOS ........................................................................................................................................... 13 \n",
    "8.3 DERRAME OU VAZAMENTO DE CHUVEIROS AUTOM√ÅTICOS (SPRINKLERS) ........................................... 14 \n",
    "8.4 DESMORONAMENTO ......................................................................................................................................... 15 \n",
    "8.5 RESPONSABILIDADE CIVIL DANOS MORAIS ................................................................................................. 16 \n",
    "8.6 RESPONSABILIDADE CIVIL CONDOM√çNIO ...................................................................................................... 17 \n",
    "8.7 RESPONSABILIDADE CIVIL GARAGISTA ........................................................................................................ 19 \n",
    "8.8 RESPONSABILIDADE CIVIL PORT√ïES AUTOM√ÅTICOS ................................................................................ 23 \n",
    "8.9 RESPONSABILIDADE CIVIL S√çNDICO .............................................................................................................. 24 \n",
    "8.10 FIDELIDADE ........................................................................................................................................................ 26 \n",
    "8.11 IMPACTO DE VE√çCULOS.................................................................................................................................... 27 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11', 'CL√ÅUSULA PARTICULAR DE EXCLUS√ÉO PARA SITUA√á√ïES NACIONAIS OU INTERNACIONAIS DE \\nSAN√á√ÉO, EMBARGO, PROIBI√á√ÉO OU RESTRI√á√ÉO', '55', 10)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_matching_patterns(pattern1, pattern2, input_string):\n",
    "    # Find all matches for both patterns using finditer to get match objects\n",
    "    matches1 = pattern1.finditer(input_string)\n",
    "    matches2 = pattern2.finditer(input_string)\n",
    "    \n",
    "    # Combine both sets of matches into a list of tuples (with offset)\n",
    "    combined_matches = []\n",
    "    \n",
    "    for match in matches1:\n",
    "        # Append a tuple with the components and the offset (match.start())\n",
    "        combined_matches.append((match.group(1), match.group(3).strip(), match.group(4), match.start()))\n",
    "    \n",
    "    for match in matches2:\n",
    "        # Append a tuple with the components and the offset (match.start())\n",
    "        combined_matches.append((match.group(1), match.group(3).strip(), match.group(4), match.start()))\n",
    "    \n",
    "    # Sort the combined list of tuples by the offset (last item in the tuple)\n",
    "    sorted_matches = sorted(combined_matches, key=lambda match: match[3])  # match[3] is the offset\n",
    "    \n",
    "    # Return the sorted list of matched components\n",
    "    return sorted_matches\n",
    "\n",
    "# Adjusted regex patterns to handle multi-line section titles\n",
    "pattern1 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\s*\\n([\\s\\S]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Pattern 1\n",
    "pattern2 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\.\\s*\\n([\\s\\S]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Pattern 2\n",
    "\n",
    "# Example input with a multi-line title\n",
    "input_string = \"\"\"\n",
    "blah blah\n",
    "11 \n",
    "CL√ÅUSULA PARTICULAR DE EXCLUS√ÉO PARA SITUA√á√ïES NACIONAIS OU INTERNACIONAIS DE \n",
    "SAN√á√ÉO, EMBARGO, PROIBI√á√ÉO OU RESTRI√á√ÉO................................................................................................... 55 \n",
    "some other random text\n",
    "\"\"\"\n",
    "\n",
    "# Call the function and print the results\n",
    "result = extract_matching_patterns(pattern1, pattern2, input_string)\n",
    "\n",
    "for match in result:\n",
    "    print(match)  # Output will include tuple with matched components and sorted by offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('7.1', '.1', 'COBERTURA B√ÅSICA AMPLA', '10'), ('7.2', '.2', 'COBERTURA B√ÅSICA SIMPLES', '11')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_section_numbers(document_content):\n",
    "    \"\"\"\n",
    "    Extracts section numbers from a given document content while handling multi-line titles correctly.\n",
    "    \n",
    "    Args:\n",
    "        document_content (str): The input string containing the document content.\n",
    "    \n",
    "    Returns:\n",
    "        list: A sorted list of unique section numbers found in the document.\n",
    "    \"\"\"\n",
    "    # Updated regex to properly match section numbers followed by a title\n",
    "    pattern = re.compile(r'^\\s*(\\d+(\\.\\d+)*)\\s*\\n([^\\n]+?)\\s*\\.+\\s*(\\d+)\\s*$', re.MULTILINE)\n",
    "\n",
    "    # Find all matches\n",
    "    matches = pattern.findall(document_content)\n",
    "\n",
    "    # Extract section numbers, ensuring correct sorting\n",
    "    extracted_sections = [(match[0], match[1], match[2], match[3]) for match in matches]\n",
    "\n",
    "    return extracted_sections\n",
    "    # Sort based on hierarchical order\n",
    "    # return sorted(set(extracted_sections), key=lambda x: [int(n) for n in x.split('.')])\n",
    "\n",
    "# Example usage\n",
    "document_text = \"\"\"\n",
    "7. \n",
    "COBERTURAS DO SEGURO .................................................................................................................................................. 10 \n",
    "7.1\n",
    "COBERTURA B√ÅSICA AMPLA ........................................................................................................................................... 10 \n",
    "7.2 \n",
    "COBERTURA B√ÅSICA SIMPLES ........................................................................................................................................ 11 \n",
    "\"\"\"\n",
    "\n",
    "# Extract section numbers\n",
    "section_numbers = extract_section_numbers(document_text)\n",
    "\n",
    "# Print results\n",
    "print(section_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_summary(input_string):\n",
    "    # Combine both sets of matches into a list of tuples (with offset)\n",
    "    combined_matches = set()\n",
    "    \n",
    "    pattern1 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\s*\\n([^\\n]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Pattern 1\n",
    "    pattern2 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\.\\s*\\n([^\\n]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Pattern 2\n",
    "\n",
    "    # Find all matches for both patterns using finditer to get match objects\n",
    "    matches1 = pattern1.finditer(input_string)\n",
    "    matches2 = pattern2.finditer(input_string)\n",
    "    \n",
    "    for match in matches1:\n",
    "        # Append a tuple with the components and the offset (match.start())\n",
    "        combined_matches.add((match.group(1), match.group(3), match.group(4), match.start(), match.end()))\n",
    "    \n",
    "    for match in matches2:\n",
    "        # Append a tuple with the components and the offset (match.start())\n",
    "        combined_matches.add((match.group(1), match.group(3), match.group(4), match.start(), match.end()))\n",
    "    \n",
    "    # Adjusted regex patterns to handle multi-line section titles\n",
    "    pattern1 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\s*\\n([\\s\\S]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Pattern 1\n",
    "    pattern2 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\.\\s*\\n([\\s\\S]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Pattern 2\n",
    "\n",
    "    # Find all matches for both patterns using finditer to get match objects\n",
    "    matches1 = pattern1.finditer(input_string)\n",
    "    matches2 = pattern2.finditer(input_string)\n",
    "    \n",
    "    for match in matches1:\n",
    "        # Append a tuple with the components and the offset (match.start())\n",
    "        combined_matches.add((match.group(1), match.group(3), match.group(4), match.start(), match.end()))\n",
    "    \n",
    "    for match in matches2:\n",
    "        # Append a tuple with the components and the offset (match.start())\n",
    "        combined_matches.add((match.group(1), match.group(3), match.group(4), match.start(), match.end()))\n",
    "\n",
    "    # Sort the combined list of tuples by the offset (last item in the tuple)\n",
    "    combined_matches = list(combined_matches)\n",
    "    sorted_matches = sorted(combined_matches, key=lambda match: match[3])  # match[3] is the offset\n",
    "    \n",
    "    # Return the sorted list of matched components\n",
    "    return sorted_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_summary(input_string):\n",
    "    \"\"\"\n",
    "    Extracts section numbers, titles, and page numbers from a document while ensuring \n",
    "    that section titles do not contain newline characters.\n",
    "    \n",
    "    Args:\n",
    "        input_string (str): The document content.\n",
    "    \n",
    "    Returns:\n",
    "        list: A sorted list of tuples (section_number, title, page_number, start_offset, end_offset),\n",
    "              excluding tuples where the title contains newlines.\n",
    "    \"\"\"\n",
    "    # Set to store unique matches\n",
    "    combined_matches = set()\n",
    "    \n",
    "    # Patterns to capture section headers with and without an extra dot\n",
    "    pattern1 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\s*\\n([^\\n]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # Without dot\n",
    "    pattern2 = re.compile(r\"\\s*(\\d+(\\.\\d+)?)\\.\\s*\\n([^\\n]+?)\\s*\\.+\\s*(\\d+)\\s*\")  # With dot\n",
    "\n",
    "    # Find matches and add to set\n",
    "    for pattern in [pattern1, pattern2]:\n",
    "        for match in pattern.finditer(input_string):\n",
    "            section_number, title, page_number = match.group(1), match.group(3), match.group(4)\n",
    "            start_offset, end_offset = match.start(), match.end()\n",
    "\n",
    "            # Exclude entries where the title contains newline characters\n",
    "            if \"\\n\" not in title:\n",
    "                combined_matches.add((section_number, title, page_number, start_offset, end_offset))\n",
    "\n",
    "    # Sort the matches by start offset\n",
    "    sorted_matches = sorted(combined_matches, key=lambda match: match[3])  # Sort by start_offset\n",
    "    \n",
    "    return sorted_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2024', 'Processo SUSEP n¬∫ 15414', '100909', 153, 189)\n",
      "('1', '√ÇMBITO GEOGR√ÅFICO', '8', 5054, 5240)\n",
      "('2', 'OBJETIVO DO SEGURO', '8', 5240, 5422)\n",
      "('3', 'DOCUMENTOS DO SEGURO', '8', 5422, 5598)\n",
      "('4', 'LOCAL DE RISCO', '8', 5598, 5786)\n",
      "('5', 'EDIF√çCIOS ABRANGIDOS PELO SEGURO', '8', 5786, 5952)\n",
      "('6', 'EDIF√çCIOS N√ÉO ABRANGIDOS PELO SEGURO', '9', 5952, 6113)\n",
      "('7', 'COBERTURAS DO SEGURO', '10', 6113, 6289)\n",
      "('10', '7', '1', 6284, 6294)\n",
      "('10', '7', '2', 6456, 6466)\n",
      "('8', 'COBERTURAS ACESS√ìRIAS', '12', 6630, 6785)\n",
      "('8.1', 'ALAGAMENTO E INUNDA√á√ÉO', '12', 6785, 6939)\n",
      "('8.2', 'DANOS EL√âTRICOS', '13', 6939, 7104)\n",
      "('8.3', 'DERRAME OU VAZAMENTO DE CHUVEIROS AUTOM√ÅTICOS (SPRINKLERS)', '14', 7104, 7216)\n",
      "('8.4', 'DESMORONAMENTO', '15', 7216, 7378)\n",
      "('8.5', 'RESPONSABILIDADE CIVIL DANOS MORAIS', '16', 7378, 7521)\n",
      "('8.6', 'RESPONSABILIDADE CIVIL CONDOM√çNIO', '17', 7521, 7667)\n",
      "('8.7', 'RESPONSABILIDADE CIVIL GARAGISTA', '19', 7667, 7814)\n",
      "('8.8', 'RESPONSABILIDADE CIVIL PORT√ïES AUTOM√ÅTICOS', '23', 7814, 7947)\n",
      "('8.9', 'RESPONSABILIDADE CIVIL S√çNDICO', '24', 7947, 8098)\n",
      "('8.10', 'FIDELIDADE', '26', 8098, 8272)\n",
      "('8.11', 'IMPACTO DE VE√çCULOS', '27', 8272, 8434)\n",
      "('8.12', 'INC√äNDIO DOS BENS DOS COND√îMINOS ‚Äì EXCLUSIVAMENTE PARA UNIDADES RESIDENCIAIS', '28', 8434, 8529)\n",
      "('8.13', 'DESPESAS COM ALUGUEL ‚Äì EXCLUSIVAMENTE PARA UNIDADES RESIDENCIAIS', '30', 8529, 8637)\n",
      "('8.14', 'DESPESAS FIXAS', '31', 8637, 8805)\n",
      "('8.15', 'QUEBRA DE VIDROS, ESPELHOS, M√ÅRMORES, AN√öNCIOS LUMINOSOS E GRANITOS', '31', 8805, 8910)\n",
      "('8.16', 'ROUBO E SUBTRA√á√ÉO DE BENS COM ARROMBAMENTO', '32', 8910, 9038)\n",
      "('34', '8', '18', 9292, 9303)\n",
      "('35', '8', '19', 9447, 9458)\n",
      "('36', '8', '20', 9579, 9590)\n",
      "('37', '8', '21', 9721, 9732)\n",
      "('9', 'EXCLUS√ïES GERAIS', '49', 9886, 10049)\n",
      "('10', 'BENS N√ÉO COMPREENDIDOS NO SEGURO', '53', 10049, 10190)\n",
      "('12', 'LIMITE M√ÅXIMO DE INDENIZA√á√ÉO/CAPITAL SEGURADO', '56', 10414, 10547)\n",
      "('13', 'LIMITE M√ÅXIMO DE INDENIZA√á√ÉO PARA COBERTURA DE RESPONSABILIDADE CIVIL', '56', 10547, 10651)\n",
      "('14', 'LIMITE M√ÅXIMO DE GARANTIA', '57', 10651, 10806)\n",
      "('15', 'P.O.S (Participa√ß√£o Obrigat√≥ria do Segurado)', '57', 10806, 10956)\n",
      "('16', 'SEGURO √Ä PRIMEIRO RISCO', '57', 10956, 11112)\n",
      "('17', 'ESTIPULANTE', '57', 11112, 11281)\n",
      "('18', 'ACEITA√á√ÉO', '58', 11281, 11452)\n",
      "('19', 'INSPE√á√ÉO', '59', 11452, 11630)\n",
      "('20', 'VIG√äNCIA DO SEGURO', '60', 11630, 11791)\n",
      "('21', 'RENOVA√á√ÉO DO SEGURO', '60', 11791, 11947)\n",
      "('22', 'PAGAMENTO DE PR√äMIO', '61', 11947, 12105)\n",
      "('23', 'ALTERA√á√ÉO DO RISCO', '64', 12105, 12265)\n",
      "('24', 'PERDA DE DIREITOS', '66', 12265, 12429)\n",
      "('25', 'PROCEDIMENTOS EM CASO DE SINISTRO', '68', 12429, 12572)\n",
      "('26', 'DOCUMENTOS B√ÅSICOS PARA SINISTRO', '69', 12572, 12715)\n",
      "('27', 'LIQUIDA√á√ÉO DE SINISTRO', '72', 12715, 12874)\n",
      "('28', 'VISTORIA DE SINISTRO', '76', 12874, 13036)\n",
      "('29', 'PERDA TOTAL', '76', 13036, 13205)\n",
      "('30', 'SALVADOS', '77', 13205, 13376)\n",
      "('31', 'CONCORR√äNCIA DE AP√ìLICE', '77', 13376, 13530)\n",
      "('32', 'REDU√á√ÉO E REINTEGRA√á√ÉO', '79', 13530, 13684)\n",
      "('33', 'RESCIS√ÉO E CANCELAMENTO', '79', 13684, 13837)\n",
      "('34', 'SUB-ROGA√á√ÉO DE DIREITOS', '80', 13837, 13992)\n",
      "('35', 'FORO', '80', 13992, 14169)\n",
      "('36', 'PRESCRI√á√ÉO', '80', 14169, 14338)\n",
      "('37', 'GLOSS√ÅRIO', '80', 14338, 14509)\n",
      "('1', 'OBJETIVO DO SEGURO', '88', 14682, 14864)\n",
      "('2', 'CONCEITO DAS COBERTURAS', '88', 14864, 15036)\n",
      "('3', 'RISCOS EXCLU√çDOS', '96', 15036, 15219)\n",
      "('4', 'CAR√äNCIA', '98', 15219, 15411)\n",
      "('5', '√ÇMBITO TERRITORIAL DE COBERTURA', '98', 15411, 15576)\n",
      "('6', 'VIG√äNCIA DO SEGURO', '98', 15576, 15757)\n",
      "('7', 'RENOVA√á√ÉO', '98', 15757, 15946)\n",
      "('8', 'ACEITA√á√ÉO', '99', 15946, 16137)\n",
      "('9', 'ACEITA√á√ÉO E INCLUS√ÉO DE SEGURADOS', '100', 16137, 16298)\n",
      "('10', 'BENEFICI√ÅRIOS', '101', 16298, 16486)\n",
      "('11', 'CAPITAL SEGURADO', '101', 16486, 16668)\n",
      "('12', 'CUSTEIO DO SEGURO', '102', 16668, 16849)\n",
      "('13', 'PAGAMENTO DE PR√äMIO', '102', 16849, 17024)\n",
      "('14', 'DOCUMENTOS B√ÅSICOS PARA SINISTRO', '106', 17024, 17184)\n",
      "('15', 'JUNTA M√âDICA', '110', 17184, 17369)\n",
      "('16', 'PER√çCIA DA SEGURADORA', '110', 17369, 17543)\n",
      "('17', 'INDENIZA√á√ÉO', '110', 17543, 17730)\n",
      "('18', 'CESSA√á√ÉO DE COBERTURA E CANCELAMENTO DO SEGURO', '111', 17730, 17871)\n",
      "('19', 'PERDA DO DIREITO', '112', 17871, 18056)\n",
      "('20', 'OBRIGA√á√ïES DO ESTIPULANTE', '113', 18056, 18225)\n",
      "('21', 'ALTERA√á√ïES DO SEGURO DURANTE A VIG√äNCIA', '113', 18225, 18379)\n",
      "('22', 'DISPOSI√á√ïES GERAIS', '113', 18379, 18561)\n",
      "('23', 'FORO', '114', 18561, 18758)\n",
      "('24', 'PRESCRI√á√ÉO', '114', 18758, 18947)\n",
      "('25', 'GLOSS√ÅRIO', '114', 18947, 19135)\n",
      "('117', 'VIDA EM GRUPO ‚Äì M√öLTIPLO SALARIAL', '119', 19330, 19507)\n",
      "('1', 'OBJETIVO DO SEGURO', '119', 19505, 19687)\n",
      "('2', 'CONCEITO DAS COBERTURAS', '119', 19687, 19865)\n",
      "('3', 'RISCOS EXCLU√çDOS', '127', 19865, 20048)\n",
      "('4', 'CAR√äNCIA', '128', 20048, 20240)\n",
      "('5', '√ÇMBITO TERRITORIAL DE COBERTURA', '128', 20240, 20405)\n",
      "('6', 'VIG√äNCIA DO SEGURO', '129', 20405, 20586)\n",
      "('7', 'RENOVA√á√ÉO', '129', 20586, 20775)\n",
      "('8', 'ACEITA√á√ÉO', '129', 20775, 20966)\n",
      "('9', 'ACEITA√á√ÉO E INCLUS√ÉO DE SEGURADOS', '131', 20964, 21127)\n",
      "('10', 'BENEFICI√ÅRIOS', '132', 21127, 21315)\n",
      "('11', 'CAPITAL SEGURADO', '133', 21315, 21497)\n",
      "('12', 'CERTIFICADO INDIVIDUAL', '134', 21497, 21676)\n",
      "('13', 'CUSTEIO DO SEGURO', '134', 21676, 21857)\n",
      "('14', 'PAGAMENTO DE PR√äMIO', '134', 21857, 22035)\n",
      "('15', 'PROCEDIMENTOS EM CASO DE SINISTROS', '138', 22035, 22196)\n",
      "('16', 'DOCUMENTOS B√ÅSICOS PARA SINISTRO', '138', 22196, 22359)\n",
      "('17', 'JUNTA M√âDICA', '142', 22359, 22547)\n",
      "('18', 'PER√çCIA DA SEGURADORA', '142', 22547, 22724)\n",
      "('19', 'INDENIZA√á√ÉO', '142', 22724, 22913)\n",
      "('20', 'CESSA√á√ÉO DE COBERTURA E CANCELAMENTO DO SEGURO', '143', 22913, 23054)\n",
      "('21', 'PERDA DO DIREITO', '144', 23054, 23239)\n",
      "('22', 'OBRIGA√á√ïES DO ESTIPULANTE', '145', 23239, 23410)\n",
      "('23', 'ALTERA√á√ïES DO SEGURO DURANTE A VIG√äNCIA', '145', 23410, 23564)\n",
      "('24', 'MATERIAL DE DIVULGA√á√ÉO', '146', 23564, 23740)\n",
      "('25', 'DISPOSI√á√ïES GERAIS', '146', 23740, 23922)\n",
      "('26', 'FORO', '146', 23922, 24119)\n",
      "('27', 'PRESCRI√á√ÉO', '146', 24119, 24308)\n",
      "('28', 'GLOSS√ÅRIO', '146', 24308, 24499)\n",
      "('7.4', 'A cobertura garantir√° ainda, at√© o limite m√°ximo de indeniza√ß√£o de R$ 2', '500', 59715, 59795)\n",
      "('31.10', 'Esta cl√°usula n√£o se aplica √†s coberturas que garantam morte e/ou invalidez', '32', 211724, 211824)\n",
      "('3.7', 'A perda de dentes e os danos est√©ticos n√£o dar√£o direito a indeniza√ß√£o por invalidez permanente por acidente', '2', 242262, 242381)\n",
      "('08', '2', '1', 252624, 252635)\n",
      "('4.2', 'N√£o haver√° car√™ncia para eventos decorrentes de acidente pessoal', '4', 263220, 263299)\n",
      "('3', 'O pagamento antecipado de pr√™mio n√£o elimina a car√™ncia estabelecida para o seguro', '4', 263300, 263391)\n",
      "('6.4', ' A data de in√≠cio de vig√™ncia do seguro somente ser√° concretizada com a aceita√ß√£o do risco pela Seguradora', '7', 264569, 264692)\n",
      "('8.12', 'A emiss√£o desta ap√≥lice ou do endosso ser√° feita em at√© 15 (quinze) dias a partir da data de aceita√ß√£o da proposta', '8', 269979, 270109)\n",
      "('9.1', 'A aceita√ß√£o do seguro estar√° sujeita √† an√°lise do risco pela Seguradora', '9', 270326, 270413)\n",
      "('13.1', 'O pr√™mio de seguro poder√° ser pago √† vista ou parcelado, mediante acordo entre as partes', '13', 276487, 276592)\n",
      "('02', 'testemunhas isentas. N√£o se aceitar√° como testemunhas pessoas do mesmo local de trabalho do Segurado/fam√≠lia', '14', 292208, 292328)\n",
      "('15', '(quinze) dias, a contar da data da contesta√ß√£o, a constitui√ß√£o de junta m√©dica', '15', 294898, 294988)\n",
      "('21.1', 'O presente seguro poder√° ser alterado, em qualquer tempo, mediante acordo entre a Seguradora e o Estipulante', '21', 305386, 305513)\n",
      "('60', '(sessenta) pontos, em um total de 80 (oitenta) pontos previstos como poss√≠veis', '2', 329360, 329449)\n",
      "('08', '2', '2', 335016, 335027)\n",
      "('4.2', 'N√£o haver√° car√™ncia para eventos decorrentes de acidente pessoal', '4', 344301, 344380)\n",
      "('3', 'O pagamento antecipado de pr√™mio n√£o elimina a car√™ncia estabelecida para o seguro', '4', 344381, 344472)\n",
      "('5.3', 'As eventuais indeniza√ß√µes ser√£o pagas no Brasil e em moeda corrente nacional', '6', 345388, 345485)\n",
      "('6.4', ' A data de in√≠cio de vig√™ncia do seguro somente ser√° concretizada com a aceita√ß√£o do risco pela Seguradora', '7', 346280, 346401)\n",
      "('9.1', 'A aceita√ß√£o do seguro estar√° sujeita √† an√°lise do risco pela Seguradora', '9', 352295, 352382)\n",
      "('11.1', 'Os Capitais Segurados ser√£o definidos na Proposta', '11', 357849, 357915)\n",
      "('14.1', 'O pr√™mio de seguro poder√° ser pago √† vista ou parcelado, mediante acordo entre as partes', '14', 360507, 360612)\n",
      "('1.2', '‚ÄúIndeniza√ß√£o‚Äù, dentro do prazo estabelecido', '14', 362101, 362154)\n",
      "('25.2', 'O registro do produto √© autom√°tico e n√£o representa aprova√ß√£o ou recomenda√ß√£o por parte da Susep', '25', 390385, 390498)\n",
      "('26.1', 'Fica eleito o foro do domic√≠lio do segurado para dirimir quaisquer d√∫vidas oriundas do presente contrato', '26', 390648, 390769)\n"
     ]
    }
   ],
   "source": [
    "input_file = \"../data/tokio_outubro_2024_cleaned.txt\"\n",
    "# input_file = \"../data/snippet.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    document_text = file.read()\n",
    "\n",
    "# Call the function and print the results\n",
    "result = extract_summary(document_text)\n",
    "\n",
    "for match in result:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_offsets(content, s1, s2):\n",
    "    \"\"\"\n",
    "    Finds the offsets in `content` where `s1` and `s2` appear separated by exactly one space or tab.\n",
    "    \n",
    "    Args:\n",
    "        content (str): The document content.\n",
    "        s1 (str): The first substring.\n",
    "        s2 (str): The second substring.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of starting offsets where `s1` and `s2` appear with a single space or tab in between.\n",
    "    \"\"\"\n",
    "    # Define the regex pattern to find occurrences of s1 and s2 separated by a space or tab\n",
    "    pattern = re.compile(rf\"({re.escape(s1)})[ \\t]({re.escape(s2)})\")\n",
    "\n",
    "    # Find all matches and store their start positions\n",
    "    offsets = [match.start() for match in pattern.finditer(content)]\n",
    "    \n",
    "    return offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limits of section 8.5: (46330, 49591)\n"
     ]
    }
   ],
   "source": [
    "current_section = \"8.5\"\n",
    "next_section = \"8.6\"\n",
    "start_offsets = find_offsets(document_text, current_section, \"RESPONSABILIDADE CIVIL DANOS MORAIS\")\n",
    "end_offsets = find_offsets(document_text, next_section, \"RESPONSABILIDADE CIVIL CONDOM√çNIO\")\n",
    "\n",
    "print(f'Limits of section {current_section}: ({start_offsets[0]}, {end_offsets[0]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_substring(content, start_offset, end_offset):\n",
    "    \"\"\"\n",
    "    Extracts a substring from `content` between `offset_start` and `offset_end`.\n",
    "\n",
    "    Args:\n",
    "        content (str): The document content.\n",
    "        offset_start (int): The starting offset (inclusive).\n",
    "        offset_end (int): The ending offset (exclusive).\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted substring.\n",
    "    \"\"\"\n",
    "    assert len(content) > end_offset\n",
    "    return content[start_offset:end_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403326\n",
      "8.5 RESPONSABILIDADE CIVIL DANOS MORAIS \n",
      " \n",
      "8.5.1 \n",
      "Riscos Cobertos \n",
      " \n",
      "Garante, at√© o Limite M√°ximo de Indeniza√ß√£o contratado o reembolso da indeniza√ß√£o pelo qual o condom√≠nio seja respons√°vel \n",
      "civilmente a pagar, em senten√ßa judicial transitada em julgado ou em acordo expressamente autorizado pela seguradora, em \n",
      "virtude de danos morais, decorrente diretamente de danos materiais e ou danos corporais involuntariamente causados a terceiros \n",
      "efetivamente indenizados nas coberturas de Responsabilidade Civil Condom√≠nio ou S√≠ndico, previstas no presente contrato.  \n",
      " \n",
      "Salvo disposi√ß√£o em contr√°rio, esta cobertura tamb√©m abrange as despesas emergenciais efetuadas pelo Segurado ao tentar \n",
      "evitar e/ou minorar os danos causados a terceiros, desde que qualquer acordo com terceiros, judicial ou extrajudicial, \n",
      "somente ser√° considerado pela Seguradora, quando submetido previamente a sua aprova√ß√£o expressa.  \n",
      " \n",
      "Para efeito deste Contrato de Seguro, caracteriza- se Dano Moral, aquele que traz como consequ√™ncia ofensa √† honra, ao afeto, √† \n",
      "liberdade, √† profiss√£o, ao respeito aos mortos, √† psique, √† sa√∫de, ao nome, ao cr√©dito, ao bem-estar e √† vida. \n",
      " \n",
      "Para todos os fins e efeitos os cond√¥minos s√£o equiparados a terceiros. \n",
      " \n",
      "8.5.2 \n",
      "Observadas as limita√ß√µes previstas neste contrato, a presente cobertura s√≥ prevalece se atendidas \n",
      "simultaneamente as seguintes condi√ß√µes: \n",
      " \n",
      "a. Que os danos sejam verificados na vig√™ncia do presente contrato;  \n",
      "b. For comprovada a exist√™ncia de manuten√ß√£o regular das m√°quinas, equipamentos e instala√ß√µes, quando necess√°ria; \n",
      "c. Na hip√≥tese de as m√°quinas, equipamentos e instala√ß√µes necessitarem de operador, estarem sendo manejados por \n",
      "pessoa habilitada no momento do acidente; \n",
      "d. Tiverem sido expostos avisos de advert√™ncia, em locais vis√≠veis, alertando para qualquer tipo de perigo para os usu√°rios \n",
      "das m√°quinas, equipamentos e instala√ß√µes; \n",
      "e. Os servi√ßos, no momento do acidente, estiverem sendo executados por pessoas habilitadas. \n",
      " \n",
      "8.5.3 \n",
      "Essa cobertura √© a base de reclama√ß√£o (claims made basis): tipo de contrata√ß√£o em que a indeniza√ß√£o a terceiros, \n",
      "pelo segurado, obedece aos seguintes requisitos: \n",
      " \n",
      "a. os danos ou o fato gerador que tenham ocorrido durante o per√≠odo de vig√™ncia da ap√≥lice, ou durante o per√≠odo de \n",
      "retroatividade; e \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "b. o terceiro apresente a reclama√ß√£o ao segurado durante a vig√™ncia da ap√≥lice, ou durante o prazo adicional caso este \n",
      "esteja estabelecido no contrato de seguro (ap√≥lice). \n",
      " \n",
      "IMPORTANTE:  \n",
      "a. A contrata√ß√£o desta cobertura est√° vinculada √† contrata√ß√£o das coberturas de Responsabilidade Civil \n",
      "Condom√≠nio e/ou Responsabilidade Civil S√≠ndico. \n",
      "b. A Seguradora poder√° intervir na a√ß√£o, na qualidade de assistente. \n",
      " \n",
      "Riscos N√£o Cobertos: \n",
      " \n",
      "Al√©m das disposi√ß√µes constantes do t√≥pico ‚ÄúEXCLUS√ïES GERAIS‚Äù acham-se tamb√©m exclu√≠dos: \n",
      " \n",
      "a. Qualquer preju√≠zo decorrente de indeniza√ß√£o punitiva por atraso ou omiss√£o do Segurado na condu√ß√£o do processo \n",
      "contra ele instaurado pelo terceiro prejudicado; \n",
      "b. Danos morais cujos nexos causais n√£o estejam relacionados √† danos materiais e/ou corporais garantidos por esta \n",
      "ap√≥lice; \n",
      "c. Multas de qualquer natureza impostas ao segurado, bem como honor√°rios relativos a a√ß√µes, processos criminais ou \n",
      "demais tipos de processos. \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract substring\n",
    "print(len(document_text))\n",
    "substring = extract_substring(document_text, start_offsets[0], end_offsets[0])\n",
    "print(substring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['metadata', 'content', 'status'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tika import parser\n",
    "\n",
    "input_file = \"../data/tokio_outubro_2024.txt\"\n",
    "output_file = \"../data/tokio_outubro_2024_tika.txt\"\n",
    "\n",
    "parsed_pdf = parser.from_file(\"../data/propostas/tokio_outubro_2024.pdf\",)\n",
    "\n",
    "raw_text = parsed_pdf['content']\n",
    "\n",
    "# Remove footers\n",
    "cleaned_text = remove_footer(raw_text)\n",
    "\n",
    "# Save cleaned text\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(cleaned_text)\n",
    "\n",
    "parsed_pdf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pdf:PDFVersion': '1.7',\n",
       " 'xmp:CreatorTool': 'Microsoft¬Æ Word para Microsoft 365',\n",
       " 'pdf:hasXFA': 'false',\n",
       " 'access_permission:can_print_degraded': 'true',\n",
       " 'X-TIKA:Parsed-By-Full-Set': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.pdf.PDFParser'],\n",
       " 'X-TIKA:content_handler': 'ToTextContentHandler',\n",
       " 'pdf:num3DAnnotations': '0',\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_SiteId': '8b7cb950-a7e7-4897-9382-00f1b86d3871',\n",
       " 'dc:format': 'application/pdf; version=1.7',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_ContentBits': '2',\n",
       " 'pdf:docinfo:creator_tool': 'Microsoft¬Æ Word para Microsoft 365',\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_ContentBits': '2',\n",
       " 'access_permission:fill_in_form': 'true',\n",
       " 'pdf:hasCollection': 'false',\n",
       " 'pdf:encrypted': 'false',\n",
       " 'pdf:containsNonEmbeddedFont': 'true',\n",
       " 'xmp:CreateDate': '2024-10-06T15:05:16Z',\n",
       " 'pdf:hasMarkedContent': 'true',\n",
       " 'xmp:ModifyDate': '2024-10-06T15:05:16Z',\n",
       " 'pdf:docinfo:creator': 'Jeberson Jose Da Silva',\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_SetDate': '2023-09-05T12:02:19Z',\n",
       " 'access_permission:extract_for_accessibility': 'true',\n",
       " 'resourceName': \"b'tokio_outubro_2024.pdf'\",\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_Enabled': 'true',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_Enabled': 'true',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_Method': 'Standard',\n",
       " 'X-TIKA:Parsed-By': ['org.apache.tika.parser.DefaultParser',\n",
       "  'org.apache.tika.parser.pdf.PDFParser'],\n",
       " 'X-TIKA:embedded_depth': '0',\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_ActionId': '6b2e7900-98a3-4337-b9e9-56f99b959fe9',\n",
       " 'pdf:annotationTypes': 'null',\n",
       " 'pdf:docinfo:producer': 'Microsoft¬Æ Word para Microsoft 365',\n",
       " 'pdf:annotationSubtypes': 'Link',\n",
       " 'pdf:containsDamagedFont': 'false',\n",
       " 'pdf:unmappedUnicodeCharsPerPage': ['0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0',\n",
       "  '0'],\n",
       " 'access_permission:modify_annotations': 'true',\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_Name': 'Geral',\n",
       " 'dc:creator': 'Jeberson Jose Da Silva',\n",
       " 'dcterms:created': '2024-10-06T18:05:16Z',\n",
       " 'dcterms:modified': '2024-10-06T18:05:16Z',\n",
       " 'xmpMM:DocumentID': 'uuid:7C4B4D1D-397C-4D63-8DBC-6442ED477EB8',\n",
       " 'pdf:overallPercentageUnmappedUnicodeChars': '0.0',\n",
       " 'pdf:docinfo:modified': '2024-10-06T18:05:16Z',\n",
       " 'Content-Length': '2297740',\n",
       " 'Content-Type': 'application/pdf',\n",
       " 'dc:language': 'pt',\n",
       " 'pdf:producer': 'Microsoft¬Æ Word para Microsoft 365',\n",
       " 'MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_Method': 'Standard',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_ActionId': '6b2e7900-98a3-4337-b9e9-56f99b959fe9',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_SetDate': '2023-09-05T12:02:19Z',\n",
       " 'pdf:totalUnmappedUnicodeChars': '0',\n",
       " 'access_permission:assemble_document': 'true',\n",
       " 'xmpTPg:NPages': '152',\n",
       " 'pdf:hasXMP': 'true',\n",
       " 'pdf:charsPerPage': ['197',\n",
       "  '1788',\n",
       "  '1612',\n",
       "  '1760',\n",
       "  '6607',\n",
       "  '8254',\n",
       "  '4920',\n",
       "  '2213',\n",
       "  '2979',\n",
       "  '2251',\n",
       "  '2398',\n",
       "  '2498',\n",
       "  '3309',\n",
       "  '2787',\n",
       "  '3069',\n",
       "  '2966',\n",
       "  '2457',\n",
       "  '3403',\n",
       "  '2850',\n",
       "  '3474',\n",
       "  '2335',\n",
       "  '3181',\n",
       "  '2597',\n",
       "  '3024',\n",
       "  '3022',\n",
       "  '3217',\n",
       "  '2678',\n",
       "  '2819',\n",
       "  '3158',\n",
       "  '2317',\n",
       "  '2556',\n",
       "  '2461',\n",
       "  '3093',\n",
       "  '2803',\n",
       "  '3241',\n",
       "  '2639',\n",
       "  '2902',\n",
       "  '2942',\n",
       "  '1978',\n",
       "  '2607',\n",
       "  '2578',\n",
       "  '2591',\n",
       "  '2754',\n",
       "  '2669',\n",
       "  '2480',\n",
       "  '2873',\n",
       "  '2321',\n",
       "  '2408',\n",
       "  '3069',\n",
       "  '3199',\n",
       "  '2285',\n",
       "  '2045',\n",
       "  '2393',\n",
       "  '2878',\n",
       "  '2890',\n",
       "  '2891',\n",
       "  '2592',\n",
       "  '3315',\n",
       "  '3182',\n",
       "  '3014',\n",
       "  '2795',\n",
       "  '3321',\n",
       "  '2617',\n",
       "  '2487',\n",
       "  '2436',\n",
       "  '2654',\n",
       "  '2349',\n",
       "  '2689',\n",
       "  '2469',\n",
       "  '1991',\n",
       "  '1965',\n",
       "  '2004',\n",
       "  '2375',\n",
       "  '1088',\n",
       "  '2219',\n",
       "  '3305',\n",
       "  '2229',\n",
       "  '3117',\n",
       "  '2707',\n",
       "  '2573',\n",
       "  '3261',\n",
       "  '2772',\n",
       "  '3249',\n",
       "  '2920',\n",
       "  '2895',\n",
       "  '2955',\n",
       "  '3066',\n",
       "  '2395',\n",
       "  '3298',\n",
       "  '2787',\n",
       "  '2762',\n",
       "  '1647',\n",
       "  '2380',\n",
       "  '3115',\n",
       "  '2504',\n",
       "  '3166',\n",
       "  '1973',\n",
       "  '2449',\n",
       "  '3281',\n",
       "  '3147',\n",
       "  '2598',\n",
       "  '2692',\n",
       "  '2726',\n",
       "  '2432',\n",
       "  '2445',\n",
       "  '2609',\n",
       "  '2342',\n",
       "  '2167',\n",
       "  '2554',\n",
       "  '2856',\n",
       "  '2913',\n",
       "  '3039',\n",
       "  '2937',\n",
       "  '2532',\n",
       "  '2883',\n",
       "  '2768',\n",
       "  '2212',\n",
       "  '2058',\n",
       "  '2151',\n",
       "  '3461',\n",
       "  '3389',\n",
       "  '3292',\n",
       "  '2093',\n",
       "  '2269',\n",
       "  '3104',\n",
       "  '3202',\n",
       "  '2154',\n",
       "  '2797',\n",
       "  '2629',\n",
       "  '3549',\n",
       "  '2932',\n",
       "  '2797',\n",
       "  '2499',\n",
       "  '2351',\n",
       "  '2480',\n",
       "  '2061',\n",
       "  '2048',\n",
       "  '2681',\n",
       "  '2178',\n",
       "  '2197',\n",
       "  '2344',\n",
       "  '2525',\n",
       "  '2907',\n",
       "  '2970',\n",
       "  '3067',\n",
       "  '1950',\n",
       "  '2866',\n",
       "  '2823',\n",
       "  '2817',\n",
       "  '1991',\n",
       "  '1767',\n",
       "  '121'],\n",
       " 'access_permission:extract_content': 'true',\n",
       " 'access_permission:can_print': 'true',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_Name': 'Geral',\n",
       " 'X-TIKA:parse_time_millis': '562',\n",
       " 'pdf:docinfo:custom:MSIP_Label_0988faac-7551-4c58-92c7-6ea9d9398ce2_SiteId': '8b7cb950-a7e7-4897-9382-00f1b86d3871',\n",
       " 'access_permission:can_modify': 'true',\n",
       " 'pdf:docinfo:created': '2024-10-06T18:05:16Z'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_pdf['metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using llmsherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install package\n",
    "# !pip install --upgrade --quiet llmsherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PDF files found: 0!\n",
      "Total time: 0:00:00.000547\n"
     ]
    }
   ],
   "source": [
    "# get all documents under the folder\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "file_location = \"../data/apolices\"\n",
    "\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "\n",
    "llmsherpa_api_url = \"http://localhost:5001/parseDocument?renderFormat=all\"\n",
    "\n",
    "pdf_files = glob.glob(file_location + '/*.pdf')\n",
    "\n",
    "print(f'#PDF files found: {len(pdf_files)}!')\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "\n",
    "# parse documents and create graph\n",
    "startTime = datetime.now()\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    print(pdf_file)\n",
    "    doc = pdf_reader.read_pdf(pdf_file)\n",
    "\n",
    "    # find the first / in pdf_file from right\n",
    "    idx = pdf_file.rfind('/')\n",
    "    pdf_file_name = pdf_file[idx+1:]\n",
    "\n",
    "    # open a local file to write the JSON\n",
    "    with open(pdf_file_name + '.json', 'w') as f:\n",
    "        # convert doc.json from a list to string\n",
    "        f.write(str(doc.json))\n",
    "\n",
    "print(f'Total time: {datetime.now() - startTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/apolices/tokio_outubro_2024.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllmsherpa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMSherpaFileLoader\n\u001b[1;32m      3\u001b[0m loader \u001b[38;5;241m=\u001b[39m LLMSherpaFileLoader(\n\u001b[1;32m      4\u001b[0m     file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/apolices/tokio_outubro_2024.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     new_indent_parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     llmsherpa_api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:5001/api/parseDocument?renderFormat=all\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/genai/lib/python3.13/site-packages/langchain_core/document_loaders/base.py:31\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/genai/lib/python3.13/site-packages/langchain_community/document_loaders/llmsherpa.py:99\u001b[0m, in \u001b[0;36mLLMSherpaFileLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllmsherpa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayoutPDFReader\n\u001b[1;32m     98\u001b[0m docs_reader \u001b[38;5;241m=\u001b[39m LayoutPDFReader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m---> 99\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mdocs_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msections\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m [\n\u001b[1;32m    103\u001b[0m         Document(\n\u001b[1;32m    104\u001b[0m             page_content\u001b[38;5;241m=\u001b[39msection\u001b[38;5;241m.\u001b[39mto_text(include_children\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m section_num, section \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(doc\u001b[38;5;241m.\u001b[39msections())\n\u001b[1;32m    112\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/genai/lib/python3.13/site-packages/llmsherpa/readers/file_reader.py:68\u001b[0m, in \u001b[0;36mLayoutPDFReader.read_pdf\u001b[0;34m(self, path_or_url, contents)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(path_or_url)\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     69\u001b[0m         file_data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     70\u001b[0m         pdf_file \u001b[38;5;241m=\u001b[39m (file_name, file_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/apolices/tokio_outubro_2024.pdf'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.llmsherpa import LLMSherpaFileLoader\n",
    "\n",
    "loader = LLMSherpaFileLoader(\n",
    "    file_path=\"../data/apolices/tokio_outubro_2024.pdf\",\n",
    "    new_indent_parser=False,\n",
    "    apply_ocr=False,\n",
    "    strategy=\"sections\",\n",
    "    llmsherpa_api_url=\"http://localhost:5001/api/parseDocument?renderFormat=all\",\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
